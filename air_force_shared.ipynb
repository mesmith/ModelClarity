{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared functions and variables used in both training and in production.\n",
    "#\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reusing the same categorical encoder from training\n",
    "#\n",
    "import category_encoders as ce\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a prefix used to identify continuous variables that have been normalized.\n",
    "# You probably don't need to change this.\n",
    "#\n",
    "norm_prefix = 'Normalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the column name used for labels after converting the input label_field\n",
    "# into 0s and 1s.  You probably don't need to change this.\n",
    "#\n",
    "generic_label = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the config file is stored.\n",
    "# At training time, the configuration is obtained from the command line.\n",
    "# Then, the training program writes the configuration into this file,\n",
    "# so at inference time, there will be no need for a command line option\n",
    "# or an environment variable to point to it.\n",
    "#\n",
    "CONFIG_FILE = 'config.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the model will be saved on disk.\n",
    "# MODEL_FILE saves in standard pytorch (Python pickle) format,\n",
    "# where ONNX_MODEL_FILE saves in interoperable ONNX format.\n",
    "#\n",
    "MODEL_FILE = 'air_force_model.pt'\n",
    "ONNX_MODEL_FILE = 'air_force_model.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the categorical and continous data encoders will be saved on disk.\n",
    "# We will need to run the exact same encoders when we run the model\n",
    "# in production.\n",
    "#\n",
    "CATEGORICAL_ENCODER_FILE='af_cat_encoder.pt'\n",
    "CONTINUOUS_ENCODER_FILE='af_continuous_encoder.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Save hyperparameters on disk as well, since we use the dataset's variables to\n",
    "# generate the hyperparameters.\n",
    "#\n",
    "HYPER_FILE = 'af_hyper.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# This returns the location where pickle files are.  These are created\n",
    "# at training time and referenced at runtime.\n",
    "#\n",
    "# In addition, we see if there is an environment variable that points\n",
    "# to a different location for the files, allowing this model to be retargeted.\n",
    "#\n",
    "def get_model_files_location():\n",
    "    if \"AF_MODEL_FILES\" in os.environ:\n",
    "        return os.environ[\"AF_MODEL_FILES\"]\n",
    "    else:\n",
    "        return '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Use this if we are hosting the app on a cloud service.  Currently unused.\n",
    "#\n",
    "def get_url_location():\n",
    "    if \"AF_MODEL_URL_PATH\" in os.environ:\n",
    "        return os.environ[\"AF_MODEL_URL_PATH\"]\n",
    "    else:\n",
    "        return '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_file_location(file):\n",
    "    return get_model_files_location() + \"/\" + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# This returns the python object that was created at training time\n",
    "#\n",
    "def read_object(file_name):\n",
    "    file = open(file_name, 'rb')\n",
    "    obj = pickle.load(file)\n",
    "    file.close\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Return the model.  Obtain the hyperparameters from disk, then\n",
    "# use them to generate the neural net.\n",
    "#\n",
    "def get_model():\n",
    "    hyper = read_object(get_file_location(HYPER_FILE))\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(hyper['input_size'], hyper['hidden_size']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Dropout(p = hyper['dropout_prob']),\n",
    "        torch.nn.Linear(hyper['hidden_size'], hyper['num_classes']),\n",
    "        torch.nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Normalize the values of the single continuous 'field'.\n",
    "# A new column named \"norm_prefix\"_\"field\" will hold the normalized values.\n",
    "#\n",
    "def normalize(data, field, norm_prefix, mean, std):\n",
    "    # Normalize using the formula: x' = (x - mean)/std.\n",
    "    # Write the x' values into a field whose name has 'norm_prefix'\n",
    "    #\n",
    "    def norm(x, mean, std):\n",
    "        return (x - mean) / std\n",
    "\n",
    "    s = pd.Series(data[field])\n",
    "    numerics = pd.to_numeric(s, errors='coerce')\n",
    "    mapped = numerics.map(lambda x: 0 if math.isnan(x) else norm(x, mean, std))\n",
    "    norm_field = norm_prefix + '_' + field\n",
    "    out = pd.DataFrame({norm_field: mapped})\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the continuous encoding in 'enc' to 'data'.\n",
    "# New columns will be created for the normalized values, and the\n",
    "# original continuous columns will be removed.\n",
    "#\n",
    "def fit_normalized(data, enc, norm_prefix):\n",
    "    with_normalized = data\n",
    "    for col_enc in enc:\n",
    "        feature = col_enc['column']\n",
    "        normalized = normalize(with_normalized, feature, norm_prefix, col_enc['mean'], col_enc['std'])\n",
    "        with_normalized = pd.concat([with_normalized, normalized], axis=1).drop([feature], axis=1)\n",
    "\n",
    "    return with_normalized"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
